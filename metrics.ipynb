{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d666fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbac21d",
   "metadata": {},
   "source": [
    "**Define the path for csv files. here, they are in the current working folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef832e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_req_duration_path = 'metric_http_req_duration.csv'\n",
    "http_req_failed_path = 'metric_http_req_failed.csv'\n",
    "vus_path = 'metric_vus.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d2afa",
   "metadata": {},
   "source": [
    "**Read csv filse as pandas data frames and keep only necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c34c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_req_duration = pd.read_csv(http_req_duration_path, usecols=['time','scenario', 'count', 'mean'], dtype={'count': 'int32', 'mean': 'float32'})\n",
    "http_req_failed = pd.read_csv(http_req_failed_path, usecols=['time', 'scenario','count', 'nz_count'], dtype={'count': 'int32', 'nz_count': 'int32'})\n",
    "vus = pd.read_csv(vus_path, usecols=['time', 'mean'], dtype={'mean': 'float32'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b3a6c",
   "metadata": {},
   "source": [
    "**rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdae3baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_req_duration = http_req_duration.rename(columns={'mean': 'response_time', 'count': 'number_of_requests'})\n",
    "http_req_failed = http_req_failed.rename(columns={'count': 'failed_request_count', 'nz_count': 'failed_request_nz_count'})\n",
    "vus = vus.rename(columns={'mean': 'vus_mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed24d126",
   "metadata": {},
   "source": [
    "**Time column includes the date as well. here, I've converted the time column to datetime and kept only the time value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6688e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_req_duration['time'] = pd.to_datetime(http_req_duration['time']).dt.time\n",
    "http_req_failed['time'] = pd.to_datetime(http_req_failed['time']).dt.time\n",
    "vus['time'] = pd.to_datetime(vus['time']).dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1b3c24",
   "metadata": {},
   "source": [
    "**Create a new column for Failure Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07482b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_req_failed['failure_rate'] = http_req_failed['failed_request_nz_count'] / http_req_failed['failed_request_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6071b2",
   "metadata": {},
   "source": [
    "**there are many duplicate values in \"http_req_duration\" datafarame.for an example, when time is 15:39:51 and scenario is \"root\" there are severl response time values.to avoid generating duplicates during the merging, I grouped them by based on both time and scenario columns.the same method was used  for the \"http_req_failed\" dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdeaa868",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_req_duration = http_req_duration.groupby(['time','scenario']).agg({\n",
    "    'number_of_requests': 'sum',\n",
    "    'response_time': 'mean'\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ee79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_req_failed = http_req_failed.groupby(['time','scenario']).agg({\n",
    "    'failed_request_count': 'sum',\n",
    "    'failed_request_nz_count': 'sum',\n",
    "    'failure_rate': 'mean'\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef1116c",
   "metadata": {},
   "source": [
    "**here http_req_duration and http_req_failed merged based on both time and scenario columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df864eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics2_req_data = pd.merge(\n",
    "    http_req_duration,\n",
    "    http_req_failed,\n",
    "    on=['time', 'scenario'],  \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e6933",
   "metadata": {},
   "source": [
    "**here, converted the merged data set in to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04dd84f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics2_req_data.to_csv('final_metrics2_req_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b9612",
   "metadata": {},
   "source": [
    "**then, again merged it with \"VUS\" dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efaef5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data = pd.merge(final_metrics2_req_data, vus, on='time', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802130e4",
   "metadata": {},
   "source": [
    "**here, I've converted the final merged data set in to a CSV file for use in Power BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf922807",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data.to_csv('metrics_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26760d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f93839",
   "metadata": {},
   "source": [
    "**set the Mysql Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07dec310",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"user name\", \n",
    "    password=\"password\",\n",
    "    database=\"metrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2300a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da43a778",
   "metadata": {},
   "source": [
    "**Drop the \"merged_metrics\" Table if its already exists to avoid duplicate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d205aff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"DROP TABLE IF EXISTS merged_metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c08af88",
   "metadata": {},
   "source": [
    "**Create the table in Mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a94c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_in_Mysql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS merged_metrics (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    time TIME,\n",
    "    scenario VARCHAR(100),\n",
    "    response_time FLOAT,\n",
    "    failed_request_count INT,\n",
    "    failed_request_nz_count INT,\n",
    "    failure_rate FLOAT,\n",
    "    number_of_requests INT,\n",
    "    vus_mean INT\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a7e3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(create_table_in_Mysql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82026f37",
   "metadata": {},
   "source": [
    "**Insert data in to the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdba7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in metrics_data.iterrows():\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO merged_metrics (time, scenario, response_time, failed_request_count, failed_request_nz_count, failure_rate, number_of_requests, vus_mean)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query, (\n",
    "        row['time'],\n",
    "        row['scenario'],\n",
    "        row['response_time'],\n",
    "        row['failed_request_count'],\n",
    "        row['failed_request_nz_count'],\n",
    "        row['failure_rate'],\n",
    "        row['number_of_requests'],\n",
    "        row['vus_mean']\n",
    "    ))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc77e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12ae63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
